{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-21T08:06:00.90738Z","iopub.execute_input":"2021-08-21T08:06:00.907739Z","iopub.status.idle":"2021-08-21T08:06:02.302238Z","shell.execute_reply.started":"2021-08-21T08:06:00.907708Z","shell.execute_reply":"2021-08-21T08:06:02.301091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/30-days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"KFold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]\ndf_test = df_test[useful_features]\n\nfor col in object_cols:\n    temp_df = []\n    temp_test_feat = None\n    for fold in range(5):\n        xtrain =  df[df.KFold != fold].reset_index(drop=True)\n        xvalid = df[df.KFold == fold].reset_index(drop=True)\n        feat = xtrain.groupby(col)[\"target\"].agg(\"mean\")\n        feat = feat.to_dict()\n        xvalid.loc[:, f\"tar_enc_{col}\"] = xvalid[col].map(feat)\n        temp_df.append(xvalid)\n        if temp_test_feat is None:\n            temp_test_feat = df_test[col].map(feat)\n        else:\n            temp_test_feat += df_test[col].map(feat)\n    \n    temp_test_feat /= 5\n    df_test.loc[:, f\"tar_enc_{col}\"] = temp_test_feat\n    df = pd.concat(temp_df)","metadata":{"execution":{"iopub.status.busy":"2021-08-21T08:06:02.30398Z","iopub.execute_input":"2021-08-21T08:06:02.304421Z","iopub.status.idle":"2021-08-21T08:06:13.731736Z","shell.execute_reply.started":"2021-08-21T08:06:02.30438Z","shell.execute_reply":"2021-08-21T08:06:13.730558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### In the code above, if we replace \"target\" with col and \"mean\" with \"count\", it becomes frequency encoding.","metadata":{}},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-21T08:06:13.734032Z","iopub.execute_input":"2021-08-21T08:06:13.734528Z","iopub.status.idle":"2021-08-21T08:06:13.77775Z","shell.execute_reply.started":"2021-08-21T08:06:13.73448Z","shell.execute_reply":"2021-08-21T08:06:13.776439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now, I will try to resubmit my codes from second submission with this modified dataset.","metadata":{}},{"cell_type":"code","source":"final_predictions = []","metadata":{"execution":{"iopub.status.busy":"2021-08-21T08:06:13.779723Z","iopub.execute_input":"2021-08-21T08:06:13.780208Z","iopub.status.idle":"2021-08-21T08:06:13.785335Z","shell.execute_reply.started":"2021-08-21T08:06:13.780148Z","shell.execute_reply":"2021-08-21T08:06:13.783871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This code is from my first submission where I used only Ordinal Encoder on the categorical columns. I decided to use\n# this also to ensemble.\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"KFold\")]\nobject_cols = [col for col in useful_features if col.startswith('cat')]\ndf_test = df_test[useful_features]\n\nscores = []\n\nfor fold in range(5):\n    xtrain = df[df.KFold != fold].reset_index(drop = True)\n    xvalid = df[df.KFold == fold].reset_index(drop = True)\n    xtest = df_test.copy()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    model = XGBRegressor(random_state = fold, tree_method = 'gpu_hist', gpu_id = 0, predictor = \"gpu_predictor\")\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(yvalid, preds_valid, squared = False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-21T08:08:19.50637Z","iopub.execute_input":"2021-08-21T08:08:19.506783Z","iopub.status.idle":"2021-08-21T08:08:43.579465Z","shell.execute_reply.started":"2021-08-21T08:08:19.506753Z","shell.execute_reply":"2021-08-21T08:08:43.578167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Standardization of the numerical features.\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"KFold\")]\nobject_cols = [col for col in useful_features if col.startswith('cat')]\nnumerical_cols = [col for col in useful_features if col.startswith(\"cont\")]\ndf_test = df_test[useful_features]\n\nscores = []\n\nfor fold in range(5):\n    xtrain =  df[df.KFold != fold].reset_index(drop = True)\n    xvalid = df[df.KFold == fold].reset_index(drop = True)\n    xtest = df_test.copy()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    scaler = preprocessing.StandardScaler()\n    xtrain[numerical_cols] = scaler.fit_transform(xtrain[numerical_cols])\n    xvalid[numerical_cols] = scaler.transform(xvalid[numerical_cols])\n    xtest[numerical_cols] = scaler.transform(xtest[numerical_cols])\n    \n    model = XGBRegressor(random_state = fold, tree_method = 'gpu_hist', gpu_id = 0, predictor = \"gpu_predictor\")\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(yvalid, preds_valid, squared = False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-21T08:13:30.744147Z","iopub.execute_input":"2021-08-21T08:13:30.74456Z","iopub.status.idle":"2021-08-21T08:13:54.977189Z","shell.execute_reply.started":"2021-08-21T08:13:30.74452Z","shell.execute_reply":"2021-08-21T08:13:54.975862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Log transformation of the numerical columns.\n# This is genrally done to include the contributions of outliers as well.\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"KFold\")]\nobject_cols = [col for col in useful_features if col.startswith('cat')]\nnumerical_cols = [col for col in useful_features if col.startswith(\"cont\")]\ndf_test = df_test[useful_features]\n\nscores = []\n\nfor col in numerical_cols:\n    df[col] = np.log1p(df[col])\n    df_test[col] = np.log1p(df_test[col])\n\nfor fold in range(5):\n    xtrain =  df[df.KFold != fold].reset_index(drop = True)\n    xvalid = df[df.KFold == fold].reset_index(drop = True)\n    xtest = df_test.copy()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    model = XGBRegressor(random_state = fold, tree_method = 'gpu_hist', gpu_id = 0, predictor = \"gpu_predictor\")\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(yvalid, preds_valid, squared = False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n","metadata":{"execution":{"iopub.status.busy":"2021-08-21T08:17:01.886034Z","iopub.execute_input":"2021-08-21T08:17:01.886488Z","iopub.status.idle":"2021-08-21T08:17:25.157978Z","shell.execute_reply.started":"2021-08-21T08:17:01.886457Z","shell.execute_reply":"2021-08-21T08:17:25.156905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#####  No improvements in almost all the models tried so far so I will not try it for the rest and not submit it. This hints us that target encoding wasn't useful for this dataset.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}